{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Example 3 verbose sensitivity analysis\nfor the analysis of your model and the calibration process\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Goals of this part of the examples:\n1. Learn how to execute a verbose sensitivity analysis\n2. Learn the meaning of the results and the analysis of your model\n3  Learn how to use the results to select tuner-parameters for a calibration\n4. Learn other sensitivity methods and compare them\n5. Learn how to execute a time dependent sensitivity analysis\n6. Learn how to save the results for reproduction\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Start by importing all relevant packages\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import warnings\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom aixcalibuha import SobolAnalyzer, FASTAnalyzer, MorrisAnalyzer\nfrom aixcalibuha.data_types import merge_calibration_classes\nfrom examples import setup_fmu, setup_calibration_classes\nfrom aixcalibuha import plotting\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Please define the missing TODOs in the section below according to the docstrings.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\"\"\"\nExample process of a verbose sensitivity analysis for calibration and analysis porpoises.\nFirst, the sensitivity problem is constructed, in this example\nthe `sobol` method is chosen.\nAfterward, the SenAnalyzer class is instantiated to run the\nsensitivity analysis in the next step.\nThe result of this analysis is then printed to the user.\nand tuner-parameters are selected with these results.\nA comparison between different methods is shown.\nAt the end the option to save a reproduction archive is shown.\n\n:param [Path, str] examples_dir:\n    Path to the examples folder of AixCaliBuHA\n    e.g. r\"LOCAL_PATH_TO\\AixCaliBuHA\\examples\"\n:param str example:\n    Which example to run, \"A\" or \"B\"\n:param int n_cpu:\n    Number of cores to use\n\n:return: A list of calibration classes\n:rtype: list\n\"\"\"\nexamples_dir = \"TODO: Add a valid input according to the docstring above\"\nexample: str  =  \"B\"\nn_cpu: int  =  1\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Setup\nSet up the class according to the documentation.\nYou just have to pass a valid simulation api and\nsome further settings for the analysis.\nLet's first load the necessary simulation api:\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "examples_dir = Path(examples_dir)\nsim_api = setup_fmu(examples_dir=examples_dir, example=example, n_cpu=n_cpu)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To conduct a sensitivity analysis, we need to define calibration classes that\nencompass the objectives (goals) for which sensitivity is to be assessed. In this\ncontext, we'll explore distinct calibration classes corresponding to various\nstates of the models. Initially, we establish a comprehensive calibration class\nthat spans the entire duration, denoted as `global`. Subsequently, we can\nleverage simulations from this global class for other classes targeting\nspecific time intervals within the overall global range.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For the specific states of the models with distinct time intervals, we adopt the\ncalibration classes from the second example and tailor them for the verbose\nsensitivity analysis. Alternatively, custom classes could be created directly\nfunction (`validation_class`), we opt to ignore it by using the variable\nassignment `_` and omit any associated text output of the second example.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "calibration_classes, _ = setup_calibration_classes(\n    examples_dir=examples_dir, example=example, multiple_classes=False\n)\nmerged_calibration_classes = merge_calibration_classes(calibration_classes)\nmerged_calibration_classes[0].name = 'global'\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, we add the calibration classes for the different states of the system\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "calibration_classes, _ = setup_calibration_classes(\n    examples_dir=examples_dir, example=example, multiple_classes=True\n)\nmerged_calibration_classes.extend(merge_calibration_classes(calibration_classes))\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This results in the following calibration classes where we merge the time intervals directly.\nWe could have also merged them with an option in the `run()` function of the\nsensitivity analyzer classes.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(\"Calibration classes for sensitivity analysis:\",\n      [c.name for c in merged_calibration_classes])\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In our detailed sensitivity analysis, it is essential for all classes to share\nidentical tuner parameters. This ensures that we can employ the same set of\nsimulations for calculating sensitivity across various calibration classes.\nHowever, the final class in example B deviates in tuner parameters; hence, we\nreset them to align with the tuner parameters of the other classes.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "if example == 'B':\n    merged_calibration_classes[-1].tuner_paras = merged_calibration_classes[0].tuner_paras\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "With the definition of the calibration classes and the loaded `sim_api`,\nwe now take a look at the different options for sensitivity analysis.\nFirst, we perform the `Sobol` method, which is the most powerful currently\nsupported method, but is also the most computational demanding one.\nAfterward, we will compare the results of the different methods.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Example of Sobol method\nFirst, we instantiate the Analyzer with the `sim_api` and the number of samples.\nFor this example we will use a small sample size to reduce the time needed,\nwhich will lead to inaccurate results.\nIn the comparison of the different methods, we will discuss the required sample size.\nWe will also define a working directory were all results of the analysis will be stored.\nAdditionally, we can choose if the samples and corresponding simulation files will be saved.\nThese files can later be loaded and used for analysis of different calibration classes\nwithout performing new simulations. The simulations during the sensitivity analysis are the\nmain computational time factor.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sen_analyzer = SobolAnalyzer(\n    sim_api=sim_api,\n    num_samples=8,\n    calc_second_order=True,\n    cd=examples_dir.joinpath('testzone', f'verbose_sen_{example}'),\n    save_files=True,\n    savepath_sim=examples_dir.joinpath('testzone', f'verbose_sen_{example}', 'files'),\n    suffix_files='csv'\n)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, we run the sensitivity analysis with the verbose option.\nWith that, we not only get the results for combined target values,\nbut we also get the results for every target value alone.\nBecause we defined the first calibration class global\nand every calibration class has the same\ntuner-parameters, we can use the option `use_first_sim`,\nwhere only the first class will be simulated and the simulation files saved.\nThese simulations will be used for all other classes.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For that the simulations are loaded for each class\nand the statistical measure is then evaluated for the\nrelevant time intervals of each class.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "When we load simulation files we can use multiprocessing for loading the simulation\nand evaluating the statistical measure for each class in their time intervals.\nThis multiprocessing option is especially\nuseful for large models and large simulation data,\nbecause only one simulation at a time is stored\nin memory for each process.\nThis can prevent possible memory errors.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We disable the automatic plot option here,\nbut we save all results. Later we can use the plot function\nof the plotting module to plot the results.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "result, classes = sen_analyzer.run(calibration_classes=merged_calibration_classes,\n                                   verbose=True,\n                                   use_first_sim=True,\n                                   plot_result=False,\n                                   save_results=True,\n                                   n_cpu=n_cpu,\n                                   scale=False)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "After running the sensitivity analysis you can see\nthat the working directory was created and the result\nfiles were saved here. First, the folder \"files\" was\ncreated as the result of `save_files=True`. In there, the\nsimulation files are stored in an own folder which\nname contains the name of the used calibration class.\nAdditionally, the corresponding samples are stored.\nThe simulations are coupled with their samples.\nAs one results of the analysis, the statistical\nmeasure and corresponding sample are saved for each class.\nThis information could be used for surrogate-based\ncalibration, which is currently not implemented in `AixCaliBuHA`.\nThe main results of the sensitivity analysis are the sensitivity\nmeasures stored in \"SobolAnalyzer_results.csv\"\nand \"SobolAnalyzer_results_second_order.csv\".\ndataframes. This is specific to the sobol method, all other\nof the sobol method with possibly other analysis variables.\nLetÂ´s take a look at these results.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The first result has as columns the tuner-parameters\nand a multi level index with three levels.\nThe first level defines the calibration class.\nThe second level defines the Goals (target values). The index `all`\nis for the result of the combined target values in the goals.\nThe last level defines the result of the\nsensitivity measure for each class and goal.\nThese analysis variables are specific for each method.\nFor their exact meaning I refer to the documentation of the SALib or the literature.\nIn this example you get a short overview in the comparison later.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(\"Result of the sensitivity analysis\")\nprint('First and total order results of sobol method')\nprint(result[0].to_string())\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The second result of the sobol method is for second order sensitive measures.\nThese describe the interaction between two parameters,\nso this dataframe has a fourth index level \"Interaction\".\nIn this level, the tuner-parameters are listed again.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('Second order results of sobol method')\nprint(result[1].to_string())\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For a better understanding of the results we will now plot them.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Plotting Sensitivity results\nWe start with the result which were calculated with the small sample size.\nLet's plot the first and total order results. These results\nare specific for each single parameter\nFor each calibration class, a figure is created\nwhich shows for each goal the first order sensitivity `S1`\nand the total order sensitivity `ST` combined. For the small\nsample size the results have large confidence\nintervals, which show that these results are inaccurate as we\nnoted earlier due to the small sample size.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plotting.plot_single(result[0])\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The plotting of second order results is only useful\nand working for more than 2 parameters.\nSo we only can take a look at them in example A.\nIf you run example B we will skip the plot of the second order results\nand load some sensitivity results of example A.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's take a look at the second order results `S2` of example A we just created.\nThis analysis variable shows the interaction of two\nparameters, so we can plot them as a heatmap.\nWe can see that the parameters have no interaction with\nthemselves what is obvious. Also, we see that the\nvalues for p1,p2 and p2,p1 are the same.\nIn the heatmap we can't visualize the confidence intervals,\nso we will also take a look at the interaction of\none specific parameter.\nFor that the `plotting` module has also a function\nwhich looks simular to the `S1` and `ST` plots.\nHere we see again large confidence intervals,\nso now we will load results which were calculated with\na much higher sample number.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "if example == 'A':\n    plotting.heatmaps(result[1])\n    plotting.plot_single_second_order(result[1], 'rad.n')\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Loading results\nWe will now load sensitivity results of example A .\nThese results were produced with this example and\na samples number N=1024 and calc_second_order=True\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "result_sobol = SobolAnalyzer.load_from_csv(\n    examples_dir.joinpath('data', 'SobolAnalyzer_results_A.csv')\n)\nresult_sobol_2 = SobolAnalyzer.load_second_order_from_csv(\n    examples_dir.joinpath('data', 'SobolAnalyzer_results_second_order_A.csv')\n)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "For a better understanding we will only take a\nlook at the global class and Electricity goal\nand plot `S1`, `ST` and `S2` in the same window.\nFor that we can use the plot function\nwith some optional options. This shows how you can easily customize\nthese plots, and you can also chang everything\non the axes of the plots.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "fig = plt.figure(figsize=plt.figaspect(1. / 4.), layout=\"constrained\")  # creating one figure\nsubfigs = fig.subfigures(1, 3, wspace=0)  # creating subfigures for each type of plot\nax0 = subfigs[0].subplots()  # plotting `S1` and `ST`\nplotting.plot_single(\n    result=result_sobol,\n    cal_classes=['global'],\n    goals=['Electricity'],\n    show_plot=False,\n    figs_axes=([subfigs[0]], [ax0]),\n    max_name_len=14\n)\nax1 = subfigs[1].subplots()  # plotting heatmap\nplotting.heatmap(\n    result_sobol_2,\n    cal_class='global',\n    goal='Electricity',\n    ax=ax1,\n    show_plot=False,\n    max_name_len=14\n)\nax2 = subfigs[2].subplots()  # plotting the interactions of one single parameter\nplotting.plot_single_second_order(\n    result=result_sobol_2,\n    para_name='rad.n',\n    show_plot=False,\n    cal_classes=['global'],\n    goals=['Electricity'],\n    figs_axes=([subfigs[2]], [ax2]),\n    max_name_len=14\n)\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, what can we see in these results? First, the\nconfidence intervals are now much smaller, so that we\ncan interpret and connect the different analysis variables.\n`S1` stands for the variance in the objective,\nwhich is caused by the variation of one parameter\nwhile all other parameters are constant. The sobol analysis\nvariables are normalized with the total variance caused\nby all parameter variations together within\ntheir bounds. This means that when the parameters had\nno interactions the sum of all `S1` values would\nbe 1. `ST` shows the resulting variance of a parameter\nwith all his interactions. Let's take a look at the\ninteraction between `n` and `G`, which are the highest.\nHere, the `S2` value of the interaction\nbetween `n` and `G` has a similar value to each difference\nof `S1` and `ST` from these parameters. This show how this\ndifference corresponds to the interactions of a parameter.\nAll other parameters have only a very small sensitivity.\nThese are just some basics, to understand what option you\nhave in `AixCaliBuAH`. For more information look up relevant literature.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Comparison of different Methods\nWe will now take a short look at a comparison of the\n`Sobol`, `Fast` and `Morris` method in `AixCaliBuAH`.\nThe `SALib` provides more methods, which can\nbe implemented here in the future or on your own.\nWe already took a look at the `Sobol` method,\nwhich can compute `S1`, `ST`, and `S2` with their confidence intervals.\nThe sobol method needs for that `(2+2k)N` simulations\nwhere `k` is the number of parameters and `N` is the sample\nnumber. For variance-based methods `N` should be greater\nthan 1000. The sobol method can also compute only `S1` and\n`ST` with calc_second_order=False and (1+k)N simulations.\nThe FAST method is another variance-based\nmethod and only computes `S1` and `ST` with k*N simulations.\n`Sobol` and FAST should show simular results which is the\ncase for example B but in example A the FAST method overestimates `ST` in some cases.\nIn the right plots, the results for the `Morris` method are shown.\nThese are based on the mean of derivatives which\nrepresents the analysis variables mu. In the estimation\nof the derivatives, only one parameter is changed at a time.\nmu_star is the mean of the absolut values of the derivatives\nand is an approximation of `ST` but\nneeds only an `N` of over 100 and `(1+k)N` simulations.\nIn this comparison, mu_star shows simular results to `ST`\nof the `Sobol` method, but it is not normalized.\nLast, sigma is computed which is the standard deviation and\nis a sign for a non-linear model or for interactions in the model.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "result_sobol = SobolAnalyzer.load_from_csv(\n    examples_dir.joinpath('data', f'SobolAnalyzer_results_{example}.csv')\n)\nresult_fast = FASTAnalyzer.load_from_csv(\n    examples_dir.joinpath('data', f'FASTAnalyzer_results_{example}.csv')\n)\nresult_morris = MorrisAnalyzer.load_from_csv(\n    examples_dir.joinpath('data', f'MorrisAnalyzer_results_{example}.csv')\n)\n\nglobal_class = classes[0]\nfig_comp = plt.figure(figsize=plt.figaspect(1. / 4.), layout=\"constrained\")\nsubfigs_comp = fig_comp.subfigures(1, 3, wspace=0)\nax0_comp = subfigs_comp[0].subplots(3, 1, sharex=True)\nplotting.plot_single(\n    result=result_sobol,\n    cal_classes=[global_class.name],\n    show_plot=False,\n    figs_axes=([subfigs_comp[0]], [ax0_comp])\n)\nsubfigs_comp[0].suptitle(\"Sobol\")\nax1_comp = subfigs_comp[1].subplots(3, 1, sharex=True)\nplotting.plot_single(\n    result=result_fast,\n    cal_classes=[global_class.name],\n    show_plot=False,\n    figs_axes=([subfigs_comp[1]], [ax1_comp])\n)\nsubfigs_comp[1].suptitle(\"FAST\")\nax2_comp = subfigs_comp[2].subplots(3, 1, sharex=True)\nplotting.plot_single(\n    result=result_morris,\n    show_plot=False,\n    cal_classes=[global_class.name],\n    figs_axes=([subfigs_comp[2]], [ax2_comp])\n)\nsubfigs_comp[2].suptitle(\"Morris\")\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Selection of tuner-parameters based on verbose sensitivity results\nWe can now also use these verbose sensitivity\nresults for a selection of relevant tuner parameters.\nWe already saw that our models have interactions,\nso it will be necessary to calibrate them together\nin one calibration class. The calibration class\nglobal can be used for that because it includes all\nthe other specific classes. But in the sensitivity\nresults of this class it could be that parameters,\nwhich are only in one state sensitive can be missed.\nWe can use the verbose sensitivity results so\nthat a parameter will be selected when it has a\nsensitivity at least in one class and target value\nof the sensitivity results. This is enough that\nthe parameter can be calibrated.\nHere, we will use `S1` because it is normalized instead of mu_star,\nand we can set on single threshold for all classes and goals.\nAlso, if a parameter is only through interaction sensitive (only in `ST`)\nA real value can't be found and the parameters which interact will\ncompensate each others deviation to a real world value.\nThis still can happen when we choose with `S1` but it is less likely.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "calibration_class = SobolAnalyzer.select_by_threshold_verbose(classes[0],\n                                                              result=result_sobol,\n                                                              analysis_variable='S1',\n                                                              threshold=0.001,\n                                                              )\n\nprint(calibration_class.tuner_paras)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Time dependent sensitivity\nFor analysis porpoises we can also evaluate the time dependent sensitivity\ninstead of the sensitivity of larger time intervals. But these results can not yet\nbe used to automatically selected tuner parameters for a calibration.\nThe function for the time dependent sensitivity is similar to the other one.\nSo we can also use the simulations of booth run functions for each other.\nThe main difference is that we only need one calibration class from which\nthe measured target data is not used and the sensitivity is directly\ncalculated for the change of the separate target values and no combined goals.\nIn the results, we then get just the additional index time.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "with warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")  # ignoring warnings that are caused by the low sample size\n    result = sen_analyzer.run_time_dependent(\n        cal_class=merged_calibration_classes[0],\n        load_sim_files=True,\n        plot_result=True\n    )\nprint(result)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "When we use the plot function we can see the sensitivity of each parameter\nchanging over time. We can also see that the confidence intervals\nare again large for such a small sample size. When the confidence interval is larger\nthan one an info is shown and the confidence interval of the previous\ntime step is used to smooth it out for the visualisation.\nLet's load again results which were created with a larger sample size.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Loading time dependent results\nThese results were produced with a samples number `N=1024` and `calc_second_order=True`\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "result_sobol_time = SobolAnalyzer.load_from_csv(\n    examples_dir.joinpath('data', 'SobolAnalyzer_results_time_A.csv')\n)\nresult_sobol_2_time = SobolAnalyzer.load_second_order_from_csv(\n    examples_dir.joinpath('data', 'SobolAnalyzer_results_second_order_time_A.csv')\n)\nplotting.plot_time_dependent(result=result_sobol_time, plot_conf=True, show_plot=False)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now the confidence intervals are smaller and\nonly at one time step they are still lager than 1.\nWe can also see that the parameter `theCon.G` has the biggest influence.\nSo we can take a closer look at this parameter with another plot\nfunction where all available sensitivity measures are plotted together.\nSecond order results are plotted cumulative on top of `S1`.\nThis resembles the definition of `ST = S1 + sum(S2_i) + sum(S3_i) + ...`\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plotting.plot_parameter_verbose(parameter='theCon.G',\n                                single_result=result_sobol_time,\n                                second_order_result=result_sobol_2_time)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "At the end we also can create a reproduction\narchive which saves all settings and all created files\nautomatically with the reproduction function of ebcpy.\nNot running in jupyter notebook\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "file = sen_analyzer.save_for_reproduction(\n    title=\"SenAnalyzerTest\",\n    path=examples_dir.joinpath('testzone'),\n    log_message=\"This is just an example\",\n    remove_saved_files=False,\n    exclude_sim_files=True\n)\nprint(\"ZIP-File to reproduce all this:\", file)\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}